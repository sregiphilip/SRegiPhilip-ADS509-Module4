{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4.1 by Sanjay Regi Philip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# functions to support text pattern functions\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    " \n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "def tokenize(text) : \n",
    "    \"\"\" Splitting on whitespace rather than the book's tokenize function. That \n",
    "        function will drop tokens like '#hashtag' or '2A', which we need for Twitter. \"\"\"\n",
    "\n",
    "    text = text.split(\" \")\n",
    "    text = list(filter(str.strip, text)) ## removes unnecessary white space characters  \n",
    "    return(text)\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text) \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)      \n",
    "    return(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# preprocess text for tokenization\n",
    "my_pipeline = [str.lower, remove_punctuation]\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            select text, party from conventions\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    convention_data = list(map(list,query_results))\n",
    "    \n",
    "for item in convention_data:\n",
    "    item[0] = prepare(item[0],my_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['montana', 'Republican'],\n",
       " ['thank you', 'Democratic'],\n",
       " ['iâ€™m mariann budde bishop of the episcopal diocese of washington dc and iâ€™m honored to offer the benediction tonight hear these words from pastor civil rights leader and peace activist william sloane coffin â€œmay god give you the grace never to sell yourself short grace to do something big for something good grace to remember that the world is too dangerous now for anything but truth and too small for anything but loveâ€ and now may the blessing of god the source of all goodness truth and love inspire you inspire us all to realize dr kingâ€™s dream of the beloved community congressman lewisâ€™s dream of a just society president lincolnâ€™s dream of a more perfect union in this country in our time amen',\n",
       "  'Democratic'],\n",
       " ['iâ€™m senator chris coons from delaware a small state where people expect to see their senators and even sometimes their vice president at the supermarket at a church festival out in their community joe fights for us because he knows our struggles and hopes he knows the pain of loss and the worries of working parents and heâ€™s always brought that same personal concern he showed for jacquelyn to getting things done as our senator and then as president obamaâ€™s vice president',\n",
       "  'Democratic'],\n",
       " ['and he knows that even the united states of america needs friends on this planet before donald trump we used to talk about american exceptionalism the only thing exceptional about the incoherent trump foreign policy is that it has made our nation more isolated than ever before joe biden knows we arenâ€™t exceptional because we bluster that we are we are exceptional because we do exceptional things on june 6th 1944 young americans gave their lives and the beaches of normandy to liberate the world from tyranny out of the ashes of that war we made peace and rebuilt the world that was and remains exceptional it is the opposite of everything donald trump stands for this moment is a fight for the security of america and the world only joe biden can make america lead like america again if you agree text join to 30330 thank you',\n",
       "  'Democratic'],\n",
       " ['nebraska', 'Republican'],\n",
       " ['millions of people and veterans and senior citizens rely on the postal system for prescription medicines for their checks',\n",
       "  'Democratic'],\n",
       " ['i work at a meatpacking plant making sure grocery store shelves stay full they call us essential workers but we get treated like weâ€™re expendable workers are dying from covid and a lot of us donâ€™t have paid sick leave or even quality protective equipment we are human beings not robots not disposable we want to keep helping you feed your family but we need a president who will have our backs nebraska cast 33 votes for our next president joe biden',\n",
       "  'Democratic'],\n",
       " ['in the most difficult times is when we stand closest together itâ€™s out of tragedy that we go stronger',\n",
       "  'Democratic'],\n",
       " ['my name is lakeisha cole i met my husband 20 years ago when we started dating while i was in college once i graduated from college we eloped two weeks after that he deployed',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2514 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    text = tokenize(text) ## tokenize the text into list of tokens\n",
    "    ret_dict = dict.fromkeys(text, \"True\") ## add tokens to dictionary\n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensure functions work as expected\n",
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words==\n",
    "       {'donald':True,'president':True}))\n",
    "assert(conv_features(\"people are american in america\",feature_words==\n",
    "                     {'america':True,'american':True,\"people\":True}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create features using convention data\n",
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = 'True'         Republ : Democr =     39.9 : 1.0\n",
      "             enforcement = 'True'         Republ : Democr =     35.8 : 1.0\n",
      "                 radical = 'True'         Republ : Democr =     35.8 : 1.0\n",
      "                   votes = 'True'         Democr : Republ =     24.6 : 1.0\n",
      "                freedoms = 'True'         Republ : Democr =     18.1 : 1.0\n",
      "                 destroy = 'True'         Republ : Democr =     16.1 : 1.0\n",
      "                  prison = 'True'         Republ : Democr =     16.1 : 1.0\n",
      "                   media = 'True'         Republ : Democr =     15.3 : 1.0\n",
      "                   trade = 'True'         Republ : Democr =     15.2 : 1.0\n",
      "                    army = 'True'         Republ : Democr =     14.0 : 1.0\n",
      "                 beliefs = 'True'         Republ : Democr =     14.0 : 1.0\n",
      "                 between = 'True'         Republ : Democr =     14.0 : 1.0\n",
      "                    isis = 'True'         Republ : Democr =     14.0 : 1.0\n",
      "                   crime = 'True'         Republ : Democr =     13.0 : 1.0\n",
      "                 defense = 'True'         Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = 'True'         Republ : Democr =     13.0 : 1.0\n",
      "                  within = 'True'         Republ : Democr =     13.0 : 1.0\n",
      "               countries = 'True'         Republ : Democr =     11.9 : 1.0\n",
      "                  defund = 'True'         Republ : Democr =     11.9 : 1.0\n",
      "                    iran = 'True'         Republ : Democr =     11.9 : 1.0\n",
      "                 violent = 'True'         Republ : Democr =     11.9 : 1.0\n",
      "                 climate = 'True'         Democr : Republ =     11.2 : 1.0\n",
      "                  earned = 'True'         Republ : Democr =     10.9 : 1.0\n",
      "                patriots = 'True'         Republ : Democr =     10.9 : 1.0\n",
      "               wonderful = 'True'         Republ : Democr =     10.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Observations\n",
    "\n",
    "It appears that the classifier works by looking for words that are most distintictive in Republican speeches vs Democratic speeches. Many of the most informative words are known to be tied closely to issues that are brought up in Republican media including topics around China, voting, crime, corruption, and more. The most informative features listed here resonate to me with what is expected to be vocalized in Republican speeches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "tweet_data = [(prepare(sublist[2].decode(), my_pipeline), sublist[1]) for sublist in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## used to create features for the new tweet sample data set\n",
    "tokens = [w for t, p in tweet_data_sample for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today i spoke on the house floor abt protecting health care for women and praised ppmarmonte for their work on the central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe #rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks its just too easy for students overwhelmed by the crushing burden of debt to pay off student loans #trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: weâ€™re grateful for our first responders our rescue personnel our firefighters our police and volunteers who have been working tirelessly to keep people safe provide muchneeded help while putting their own lives on the line\n",
      "\n",
      "httpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: letâ€™s make it even greater  #kag ðŸ‡ºðŸ‡¸ httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: we have about 1hr until the cavs tie up the series 22 im #allin216 repbarbaralee you scared #roadtovictory\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats to belliottsd on his new gig at sd city hall we are glad you will continue to serveâ€¦ httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: we are really close we have over 3500 raised toward the match right now whoot thatâ€™s 7000 for the nonmath majors in the room ðŸ˜‚ help us get there httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today the comment period for potusâ€™s plan to expand offshore drilling opened to the public you have 60 days until march 9 to share why you oppose the proposed program directly with the trump administration comments can be made by email or mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastlaâ€™s 22 years of eastside commitment amp saluted community leaders at last nightâ€™s awards dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = classifier.classify(conv_features(tweet,feature_words))\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create features for larger tweet tokens dataset\n",
    "tokens = [w for t, p in tweet_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(conv_features(tweet,feature_words))\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3982, 'Democratic': 296}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 5274, 'Democratic': 450})})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "The results show that this Naive Bayes classifier seems to perform well when predicting Republican texts but not very well at prediciting Democrat texts. \n",
    "This is supported by the fact that the accuracy is roughly 44%, Precision is roughly 93%, and Recall is 43%. This shows that the model performs well when prediciting for the positive class, which in this model is Republican, but not very well at prediciting the negative class of this model which is Democrat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
